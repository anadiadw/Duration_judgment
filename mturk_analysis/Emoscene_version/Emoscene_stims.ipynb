{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## package loading and stim paths:\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral/7003.jpg',\n",
       " 'neutral/scene_p10.jpg',\n",
       " 'neutral/scene_p3.jpg',\n",
       " 'neutral/scene_p2.jpg',\n",
       " 'neutral/Landscapes_084_v.jpg',\n",
       " 'neutral/scene_p9.jpg',\n",
       " 'neutral/scene_p8.jpg',\n",
       " 'neutral/scene_p5.jpg',\n",
       " 'neutral/scene_p7.jpg',\n",
       " 'neutral/scene_p11.jpg',\n",
       " 'neutral/scene_p6.jpg',\n",
       " 'neutral/7180.jpg',\n",
       " 'neutral/scene_c2.jpg',\n",
       " 'neutral/Landscapes_076_h.jpg',\n",
       " 'neutral/scene_p12.jpg',\n",
       " 'neutral/scene_p4.jpg',\n",
       " 'neutral/scene_p1.jpg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv('/Users/ayesh/Downloads/tst_emoscene_task_2023-12-18_13h21.57.991.csv')\n",
    "tst_files1 = tst.col_val1\n",
    "tst_files2 = tst.col_val2\n",
    "neut_folder = '/Users/ayesh/Desktop/Gradstuff/duration_judgement/cat_emoscene/neutral/'\n",
    "dir_files = ['neutral/' + f for f in listdir(neut_folder)]\n",
    "diff1 = list(set(dir_files) - set(tst_files1))\n",
    "diff2 = list(set(dir_files) - set (tst_files2))\n",
    "tts = list(set(diff1) & set(diff2))\n",
    "tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animals_001_h\n",
      "Animals_008_v\n",
      "Animals_012_h\n",
      "Animals_013_h\n",
      "Animals_016_h\n",
      "Animals_018_h\n",
      "Animals_019_h\n",
      "Animals_023_h\n",
      "Animals_024_h\n",
      "Animals_025_h\n",
      "Animals_027_h\n",
      "Animals_029_v\n",
      "Animals_032_h\n",
      "Animals_033_h\n",
      "Animals_034_h\n",
      "Animals_036_h\n",
      "Animals_037_h\n",
      "Animals_038_h\n",
      "Animals_039_h\n",
      "Animals_041_h\n",
      "Animals_042_h\n",
      "Animals_045_h\n",
      "Animals_048_h\n",
      "Animals_050_h\n",
      "Animals_052_v\n",
      "Animals_054_h\n",
      "Animals_056_h\n",
      "Animals_060_h\n",
      "Animals_061_h\n",
      "Animals_062_h\n",
      "Animals_063_h\n",
      "Animals_065_h\n",
      "Animals_067_h\n",
      "Animals_068_h\n",
      "Animals_071_h\n",
      "Animals_073_h\n",
      "Animals_074_h\n",
      "Animals_075_h\n",
      "Animals_076_v\n",
      "Animals_077_h\n",
      "Animals_078_h\n",
      "Animals_084_h\n",
      "Animals_143_h\n",
      "Animals_151_v\n",
      "Animals_207_h\n",
      "Animals_221_h\n",
      "Faces_003_h\n",
      "Faces_007_h\n",
      "Faces_009_h\n",
      "Faces_010_h\n",
      "Faces_013_h\n",
      "Faces_014_h\n",
      "Faces_016_h\n",
      "Faces_018_h\n",
      "Faces_019_h\n",
      "Faces_021_h\n",
      "Faces_025_h\n",
      "Faces_027_h\n",
      "Faces_028_h\n",
      "Faces_031_v\n",
      "Faces_032_h\n",
      "Faces_034_h\n",
      "Faces_038_h\n",
      "Faces_041_h\n",
      "Faces_143_v\n",
      "Faces_144_h\n",
      "Faces_145_v\n",
      "Faces_146_h\n",
      "Faces_147_v\n",
      "Faces_148_h\n",
      "Faces_149_v\n",
      "Faces_150_h\n",
      "Faces_151_v\n",
      "Faces_152_h\n",
      "Faces_153_v\n",
      "Faces_158_h\n",
      "Faces_159_h\n",
      "Faces_163_h\n",
      "Faces_164_h\n",
      "Faces_170_h\n",
      "Faces_172_h\n",
      "Faces_174_h\n",
      "Faces_176_h\n",
      "Faces_265_h\n",
      "Faces_269_v\n",
      "Faces_270_h\n",
      "Faces_271_h\n",
      "Faces_272_h\n",
      "Faces_273_h\n",
      "Faces_274_h\n",
      "Faces_280_h\n",
      "Faces_283_h\n",
      "Faces_284_h\n",
      "Faces_285_h\n",
      "Faces_287_h\n",
      "Faces_290_h\n",
      "Faces_291_h\n",
      "Faces_293_h\n",
      "Faces_294_h\n",
      "Faces_298_h\n",
      "Faces_299_h\n",
      "Faces_300_h\n",
      "Faces_302_h\n",
      "Faces_362_v\n",
      "Faces_363_v\n",
      "Faces_364_v\n",
      "Faces_365_v\n",
      "Faces_366_h\n",
      "Faces_367_h\n",
      "Faces_368_h\n",
      "Faces_369_v\n",
      "Faces_370_h\n",
      "Faces_371_v\n",
      "Landscapes_002_h\n",
      "Landscapes_005_h\n",
      "Landscapes_007_h\n",
      "Landscapes_022_h\n",
      "Landscapes_025_h\n",
      "Landscapes_026_h\n",
      "Landscapes_029_v\n",
      "Landscapes_118_v\n",
      "Landscapes_139_h\n",
      "Landscapes_177_h\n",
      "Objects_001_h\n",
      "Objects_002_h\n",
      "Objects_003_h\n",
      "Objects_004_h\n",
      "Objects_006_h\n",
      "Objects_007_h\n",
      "Objects_013_h\n",
      "Objects_021_v\n",
      "Objects_022_h\n",
      "Objects_023_v\n",
      "Objects_105_h\n",
      "Objects_121_v\n",
      "Objects_125_h\n",
      "Objects_126_h\n",
      "Objects_132_h\n",
      "Objects_139_h\n",
      "Objects_143_h\n",
      "Objects_148_h\n",
      "Objects_149_h\n",
      "Objects_154_h\n",
      "Objects_157_h\n",
      "Objects_202_h\n",
      "Objects_283_h\n",
      "Objects_285_h\n",
      "Objects_328_h\n",
      "People_001_h\n",
      "People_002_v\n",
      "People_003_h\n",
      "People_004_h\n",
      "People_005_h\n",
      "People_006_h\n",
      "People_007_h\n",
      "People_008_h\n",
      "People_009_h\n",
      "People_010_h\n",
      "People_011_h\n",
      "People_013_v\n",
      "People_015_h\n",
      "People_016_h\n",
      "People_017_h\n",
      "People_018_h\n",
      "People_019_v\n",
      "People_020_h\n",
      "People_021_h\n",
      "People_022_h\n",
      "People_023_h\n",
      "People_025_v\n",
      "People_031_v\n",
      "People_032_h\n",
      "People_033_h\n",
      "People_034_h\n",
      "People_037_h\n",
      "People_038_h\n",
      "People_039_v\n",
      "People_040_h\n",
      "People_058_h\n",
      "People_070_v\n",
      "People_071_h\n",
      "People_072_v\n",
      "People_073_v\n",
      "People_074_v\n",
      "People_075_v\n",
      "People_077_v\n",
      "People_081_v\n",
      "People_084_h\n",
      "People_086_h\n",
      "People_088_v\n",
      "People_090_v\n",
      "People_098_h\n",
      "People_123_h\n",
      "People_124_h\n",
      "People_125_h\n",
      "People_127_h\n",
      "People_128_h\n",
      "People_129_h\n",
      "People_133_h\n",
      "People_136_h\n",
      "People_139_h\n",
      "People_140_h\n",
      "People_142_h\n",
      "People_143_h\n",
      "People_144_h\n",
      "People_147_h\n",
      "People_198_h\n",
      "People_199_v\n",
      "People_200_h\n",
      "People_201_v\n",
      "People_202_h\n",
      "People_204_v\n",
      "People_205_v\n",
      "People_206_h\n",
      "People_207_v\n",
      "People_208_h\n",
      "People_209_v\n",
      "People_211_v\n",
      "People_212_h\n",
      "People_213_v\n",
      "People_214_h\n",
      "People_215_h\n",
      "People_216_h\n",
      "People_217_h\n",
      "People_218_v\n",
      "People_219_h\n",
      "People_220_h\n",
      "People_221_h\n",
      "People_222_h\n",
      "People_223_h\n",
      "People_224_h\n",
      "People_225_h\n",
      "People_226_h\n",
      "People_227_h\n",
      "People_228_h\n",
      "People_229_h\n",
      "People_230_h\n",
      "People_231_h\n",
      "People_232_h\n",
      "People_233_h\n",
      "People_234_h\n",
      "People_235_h\n",
      "People_237_h\n",
      "People_238_h\n",
      "People_239_h\n",
      "People_240_h\n",
      "People_241_h\n",
      "People_242_v\n",
      "People_243_h\n",
      "People_244_v\n",
      "People_246_h\n"
     ]
    }
   ],
   "source": [
    "rating_list = pd.read_csv('/Users/ayesh/Downloads/NAPS_ratings(from_Maureen).csv')\n",
    "selc = []\n",
    "ar = rating_list.AroM\n",
    "val = rating_list.ValM\n",
    "neut = []\n",
    "neg = []\n",
    "for index, row in rating_list.iterrows():\n",
    "    if  (4.5 <= val[index] <= 5.5) and (4 <= ar[index] <= 6):\n",
    "        neut.append(rating_list.ID[index])\n",
    "    if  (val[index] < 4.5) and (ar[index] >= 6):\n",
    "        print(rating_list.ID[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative/1090.jpg',\n",
       " 'negative/1111.jpg',\n",
       " 'negative/1220.jpg',\n",
       " 'negative/1271.jpg',\n",
       " 'negative/1274.jpg',\n",
       " 'negative/1300.jpg',\n",
       " 'negative/1390.jpg',\n",
       " 'negative/1930.jpg',\n",
       " 'negative/2691.jpg',\n",
       " 'negative/2692.jpg',\n",
       " 'negative/2751.jpg',\n",
       " 'negative/3195.jpg',\n",
       " 'negative/3210.jpg',\n",
       " 'negative/3211.jpg',\n",
       " 'negative/3212.jpg',\n",
       " 'negative/3230.jpg',\n",
       " 'negative/6020.jpg',\n",
       " 'negative/6212.jpg',\n",
       " 'negative/6260.jpg',\n",
       " 'negative/6312.jpg',\n",
       " 'negative/6313.jpg',\n",
       " 'negative/6510.jpg',\n",
       " 'negative/6520.jpg',\n",
       " 'negative/6550.jpg',\n",
       " 'negative/6571.jpg',\n",
       " 'negative/6821.jpg',\n",
       " 'negative/6836.jpg',\n",
       " 'negative/6840.jpg',\n",
       " 'negative/6940.jpg',\n",
       " 'negative/7135.jpg',\n",
       " 'negative/7136.jpg',\n",
       " 'negative/7360.jpg',\n",
       " 'negative/9075.jpg',\n",
       " 'negative/9163.jpg',\n",
       " 'negative/9184.jpg',\n",
       " 'negative/9230.jpg',\n",
       " 'negative/9250.jpg',\n",
       " 'negative/9270.jpg',\n",
       " 'negative/9295.jpg',\n",
       " 'negative/9340.jpg',\n",
       " 'negative/9403.jpg',\n",
       " 'negative/9410.jpg',\n",
       " 'negative/9412.jpg',\n",
       " 'negative/9413.jpg',\n",
       " 'negative/9414.jpg',\n",
       " 'negative/9433.jpg',\n",
       " 'negative/9491.jpg',\n",
       " 'negative/9520.jpg',\n",
       " 'negative/9530.jpg',\n",
       " 'negative/9560.jpg',\n",
       " 'negative/9590.jpg',\n",
       " 'negative/9600.jpg',\n",
       " 'negative/9610.jpg',\n",
       " 'negative/9621.jpg',\n",
       " 'negative/9622.jpg',\n",
       " 'negative/9623.jpg',\n",
       " 'negative/9630.jpg',\n",
       " 'negative/9904.jpg',\n",
       " 'negative/9905.jpg',\n",
       " 'negative/9908.jpg',\n",
       " 'negative/9909.jpg',\n",
       " 'negative/9911.jpg',\n",
       " 'negative/9920.jpg',\n",
       " 'negative/9921.jpg',\n",
       " 'negative/9922.jpg',\n",
       " 'negative/9927.jpg',\n",
       " 'negative/9930.jpg',\n",
       " 'negative/9940.jpg',\n",
       " 'negative/9941.jpg',\n",
       " 'negative/Faces_007_h.jpg',\n",
       " 'negative/Faces_018_h.jpg',\n",
       " 'negative/Faces_284_h.jpg',\n",
       " 'negative/Faces_290_h.jpg',\n",
       " 'negative/Landscapes_007_h.jpg',\n",
       " 'negative/Landscapes_022_h.jpg',\n",
       " 'negative/Landscapes_026_h.jpg',\n",
       " 'negative/Landscapes_139_h.jpg',\n",
       " 'negative/People_001_h.jpg',\n",
       " 'negative/People_002_v.jpg',\n",
       " 'negative/People_038_h.jpg',\n",
       " 'negative/People_040_h.jpg',\n",
       " 'negative/People_124_h.jpg',\n",
       " 'negative/People_125_h.jpg',\n",
       " 'negative/People_128_h.jpg',\n",
       " 'negative/People_142_h.jpg',\n",
       " 'negative/People_144_h.jpg',\n",
       " 'negative/People_200_h.jpg',\n",
       " 'negative/People_205_v.jpg',\n",
       " 'negative/People_235_h.jpg',\n",
       " 'negative/People_238_h.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###IAPS scenes- Negative (valence: 1–4.5; arousal: 5–9), and Neutral (valence: 4.5–5.5; arousal: 1.5–3.7)\n",
    "## NAPS scenes- Negative (valence: 1–4.5; arousal: 6+), and Neutral (valence: 4.5–5.5; arousal: 4-6)\n",
    "scenes_ls = []\n",
    "stim_dir = '/Users/ayesh/Desktop/Gradstuff/duration_judgement/cat_emoscene/negative/'\n",
    "scenes = [f for f in listdir(stim_dir)]\n",
    "for c in scenes:\n",
    "    scenes_ls.append('negative/'+ c)\n",
    "scenes_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from prior life (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file= '/Users/ayesh/Desktop/Gradstuff/online_project/IAPS_2008_1-20/IAPS_Tech_Report/AllSubjects_1-20.txt'\n",
    "allstims_dir = '/Users/ayesh/Desktop/Gradstuff/online_project/IAPS_2008_1-20/IAPS1-20Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort IAPS images by valence\n",
    "\n",
    "df=open(ratings_file,\"r\") \n",
    "a =df.readlines()\n",
    "lines = a[7:]\n",
    "\n",
    "filtered_neutral = []\n",
    "filtered_negative = []\n",
    "\n",
    "for x in lines:\n",
    "    if (x.split('\\t')[6])!='.':\n",
    "        valence = float(x.split('\\t')[2])\n",
    "        arousal = float(x.split('\\t')[4])\n",
    "    \n",
    "    ##Negative (valence: 1–4.5; arousal: 5–9), and Neutral (valence: 4.5–5.5; arousal: 1.5–3.7)\n",
    "    \n",
    "        if valence <= 4.5 and arousal >= 5:\n",
    "            filtered_negative.append(x)\n",
    "        if (4.5 < valence <= 5.5) and arousal <= 4.1: #3.7: #yields 95 pics but only 20 usable cz objects and faces\n",
    "            filtered_neutral.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dir = '/Users/ayesh/Desktop/Gradstuff/online_project/filtered_stims/'\n",
    "allneg = []\n",
    "allneu = []\n",
    "with open(\"%sneutral.txt\"%(filter_dir), 'w') as filehandle:\n",
    "    for a in filtered_neutral:\n",
    "        valence = a.split('\\t')[2]\n",
    "        arousal = a.split('\\t')[4]\n",
    "        picname = a.split('\\t')[0]\n",
    "        picnum = a.split('\\t')[1]\n",
    "        allneu.append(picnum + '.jpg')\n",
    "        filehandle.write(picname + \"\\t\" + picnum + \"\\t\" + valence + \"\\t\" + arousal +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(allstims_dir) if isfile(join(allstims_dir, f))]\n",
    "\n",
    "filter_neu = '/Users/ayesh/Desktop/Gradstuff/online_project/filtered_stims/neutral/'\n",
    "\n",
    "for a in onlyfiles:\n",
    "    if a in allneu:\n",
    "        stimsrca= os.path.join(allstims_dir, a)\n",
    "        stimsrc = stimsrca.replace(\"\\\\\", '/')\n",
    "        shutil.copy(stimsrc, filter_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making csvs from the filtered stims:\n",
    "neg_stims = '/Users/ayesh/Desktop/Gradstuff/online_project/filtered_stims/negative/filtered_neg/'\n",
    "neu_stims = '/Users/ayesh/Desktop/Gradstuff/online_project/filtered_stims/neutral/filtered_neu/'\n",
    "object_stims = '/Users/ayesh/Desktop/Gradstuff/online_project/best256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neus = [pic for pic in listdir(neu_stims) if isfile(join(neu_stims, pic))]\n",
    "negs = [npic for npic in listdir(neg_stims) if isfile(join(neg_stims, npic))]\n",
    "obj = [stim for stim in listdir(object_stims) if isfile(join(object_stims, stim))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neus_csv =[]\n",
    "negs_csv =[]\n",
    "obj_csv =[]\n",
    "\n",
    "for a in negs:\n",
    "    negs_csv.append('Images/demo/places/' + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negs_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(negs_csv, columns=[\"negative_context\"])\n",
    "df.to_csv('negative_contexts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
